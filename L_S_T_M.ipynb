{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gt3yxh4_L8Dm"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "import numpy as py\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Embedding , LSTM , SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read and load data\n",
        "data = pd.read_csv('/content/Sentiment.csv')\n",
        "#select important features\n",
        "data = data[['text','sentiment']]"
      ],
      "metadata": {
        "id": "_0K2720jMFJk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#expcetion neutral case from lable sentiment\n",
        "data = data[data.sentiment != 'Neutral']\n",
        "#lambda func:- create function without name\n",
        "#where x is parametar, x.lower is the return\n",
        "#data['text'].apply represent call by value to x\n",
        "data['text']= data['text'].apply(lambda x: x.lower()) # transformation upper case to lower\n",
        "data['text']= data['text'].apply(lambda x:re.sub(r'[^a-zA-Z0-9\\s]','',x)) #Determine the things I want in the speech"
      ],
      "metadata": {
        "id": "P_9Q_tthMsjZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in data.iterrows():\n",
        "  row[0] = row[0].replace('rt',' ') # replace rt with a space"
      ],
      "metadata": {
        "id": "6MiBwp-4Mwp-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features=2000 # the variable is represent dictionary\n",
        "\n",
        "#tokenizer is a class Responsible for dividing the sentence, as it divides every space\n",
        "#create object from tokenizer class and give it two variables, one is the size of the dictionary and the other is the thing I want to divide from\n",
        "tokenizer= Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "x = tokenizer.texts_to_sequences(data['text'].values)\n",
        "\n",
        "x= pad_sequences(x) #To make all sentences equal, where each sentence will be equal to the longest sentence in text label"
      ],
      "metadata": {
        "id": "wPiGEpXdM6NK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim =128 ## represent numbers of weights\n",
        "lstm_out=196 ## represent numbers of units\n",
        "\n",
        "model= Sequential()\n",
        "#Embedding is the first layer in the model Responsible for give Giving words that are close or that have a relationship between them similar values\n",
        "#max_features --> dictionary\n",
        "#embed_dim --> numbers of weights\n",
        "#input_length --> It represents the input of the layer\n",
        "model.add(Embedding(max_features, embed_dim,input_length=x.shape[1]))\n",
        "\n",
        "#drop from output of the Embedding layers to  prevent happening overfitting\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "\n",
        "#lstm layers tekes 3 variables\n",
        "#lstm_out --> numbers of units\n",
        "#dropout --> represent a random drop to the input\n",
        "#recurrent_dropout--> represent a random drop to the recurrent\n",
        "model.add(LSTM(lstm_out, dropout=0.2 , recurrent_dropout= 0.2))\n",
        "\n",
        "model.add(Dense(2,'softmax'))\n",
        "model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "\n",
        "y=pd.get_dummies(data['sentiment']).values ## one hot incoding"
      ],
      "metadata": {
        "id": "0lndZNx_M9G_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test ,y_train, y_test= train_test_split(x,y, test_size=0.2,random_state=32)"
      ],
      "metadata": {
        "id": "ukDca-EsNDPP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=5 , batch_size=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrFZOLK5NGPE",
        "outputId": "16db6ff5-0aa8-4901-a038-5c0141197e13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "287/287 [==============================] - 47s 151ms/step - loss: 0.4223 - accuracy: 0.8217\n",
            "Epoch 2/5\n",
            "287/287 [==============================] - 49s 170ms/step - loss: 0.3190 - accuracy: 0.8635\n",
            "Epoch 3/5\n",
            "287/287 [==============================] - 50s 175ms/step - loss: 0.2766 - accuracy: 0.8829\n",
            "Epoch 4/5\n",
            "287/287 [==============================] - 44s 154ms/step - loss: 0.2477 - accuracy: 0.8981\n",
            "Epoch 5/5\n",
            "287/287 [==============================] - 43s 151ms/step - loss: 0.2224 - accuracy: 0.9075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7874298db130>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgLcJwMeNIUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}